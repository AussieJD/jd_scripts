#!/bin/bash
#
# create a list of http: links for sharepoint files
#
## VAR
#DATE1=`date +%Y%m%d-%H%M%S`
DATE1=`date +%Y%m%d`
DEST="/Volumes/apj_ito_transformation_dct/msf/Shared Documents/APJ DCT UNIX/LST-FILE-LINKS"
VAR1="http://ent212.sharepoint.hp.com/teams/apj_ito_transformation_dct/sp_dcc/Burwood%20%20Sysmc/EDS%20Leveraged%20-%20Leveraged%20Services%20and%20Tools"

FOLDER1="/Volumes/apj_ito_transformation_dct/sp_dcc/Burwood  Sysmc/EDS Leveraged - Leveraged Services and Tools/Deliverables"
FOLDER2="/Volumes/apj_ito_transformation_dct/sp_dcc/Burwood  Sysmc/EDS Leveraged - Leveraged Services and Tools/LST CMO Discovery"
FOLDER3="/Volumes/apj_ito_transformation_dct/sp_dcc/Burwood  Sysmc/EDS Leveraged - Leveraged Services and Tools/Technical Forum Working Folder/UVH"

# FUNCTIONS
#

loopme(){

echo "...processing: $1"
cd "$1"
PWD1=`pwd | sed -e "s/\/\$//" -e "s/.*\///"`		# get last field (or folder name)
FILE1="$count.folder.list" 				# list of files - in a temporary file (to avoid Share Point time outs)
FILE2="$DATE1.lst.file.links.$PWD1.JD.html"		# HTML page - filename base for the output file

[ -f "/tmp/$FILE1" ] && rm "/tmp/$FILE1"
[ -f "/tmp/$FILE2" ] && rm "/tmp/$FILE2"

# find all files, and write to temp file1
find "$1" | sort >> "$FILE1"

printf "---- generated by file-links.sh on $DATE1 ----\n" >> /tmp/$FILE2

# read the file info from FILE1 create the html in a second file FILE2
cat "$FILE1" | while read line 

 do
	echo "<a href=\"$VAR1/$line\">$PWD1: $line</a><br>" $'\r' >> "/tmp/$FILE2"
done

echo "Writing output to: $DEST/$FILE2"
cp "/tmp/$FILE2" "$DEST/"
echo $?
[ $? -eq 0 ] 	&& a=`ls | grep $PWD1 | grep -v $DATE1` \
		&& echo "will archive previous file\(s\) $a"
echo ""
}

# SCRIPT
clear
count=1
loopme "$FOLDER1" 
count=2
loopme "$FOLDER2" 
count=3
loopme "$FOLDER3" 
wait

# nice to have later
# keep 5 copies
#copies=5
#for i in `ls -dt "$DEST/$STEM1"*`
# do
#	if [ $copies -gt 0 ] ; then copies=$(( $copies - 1 ));echo copies=$copies ; else echo "rm ${i}" ; fi
#done

# The End !
